# Redis configuration
# For docker-compose: redis://redis:6379/0
# For local development: redis://localhost:6379/0
REDIS_URL=redis://redis:6379/0

# API authentication token for gateway clients (plain text, will be base64-encoded in headers)
APIPROXY_AUTH_TOKEN=timeline

# Logging configuration
LOG_LEVEL=INFO
# Uncomment to force a specific timezone for log timestamps (e.g., Asia/Shanghai)
# LOG_TIMEZONE=Asia/Shanghai

############################
# Multi-provider routing  ##
############################

# Comma-separated provider ids used by the multi-provider routing layer.
# Example: openai,azure,local
LLM_PROVIDERS=openai,azure,local

# OpenAI provider configuration
LLM_PROVIDER_openai_NAME=OpenAI
LLM_PROVIDER_openai_BASE_URL=https://api.openai.com
LLM_PROVIDER_openai_API_KEY=sk-your-openai-api-key
LLM_PROVIDER_openai_MODELS_PATH=/v1/models
LLM_PROVIDER_openai_WEIGHT=3
LLM_PROVIDER_openai_REGION=global
LLM_PROVIDER_openai_COST_INPUT=0.003
LLM_PROVIDER_openai_COST_OUTPUT=0.006
LLM_PROVIDER_openai_MAX_QPS=50

# Azure OpenAI provider configuration
LLM_PROVIDER_azure_NAME=Azure OpenAI
LLM_PROVIDER_azure_BASE_URL=https://your-resource.openai.azure.com
LLM_PROVIDER_azure_API_KEY=your-azure-api-key
LLM_PROVIDER_azure_MODELS_PATH=/openai/models
LLM_PROVIDER_azure_WEIGHT=2
LLM_PROVIDER_azure_REGION=us-east
LLM_PROVIDER_azure_COST_INPUT=0.0025
LLM_PROVIDER_azure_COST_OUTPUT=0.005
LLM_PROVIDER_azure_MAX_QPS=100

# Local model provider configuration (optional)
LLM_PROVIDER_local_NAME=Local Model
LLM_PROVIDER_local_BASE_URL=http://localhost:8080
LLM_PROVIDER_local_API_KEY=not-required
LLM_PROVIDER_local_MODELS_PATH=/v1/models
LLM_PROVIDER_local_WEIGHT=1
LLM_PROVIDER_local_REGION=local
